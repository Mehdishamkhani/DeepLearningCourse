{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parastou naghavi - machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " داده های ترین را با تابع زیر  ایمپورت کرده و به دیتافریم تبدیل کرده"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5= pd.HDFStore('Train.h5','r+')\n",
    "df = h5.get(\"/df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "مقدار نامشخص را با صقر جایگزین کرده"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای حذف داده های اوتلایر از فیچر های عددی را انتخاب کرده و از فرمول زیر برای جذف آن ها استفاده کرده"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_numeric = df[['Favs','RTs','Followers','Following','Listed', 'likes','tweets','reply']]\n",
    "#df_numeric[np.abs(df_numeric.values - df_numeric.values.mean()) <= (3*df_numeric.values.std())]\n",
    "df_numeric[~(np.abs(df_numeric.values-df_numeric.values.mean()) > (3*df_numeric.values.std()))]\n",
    "df_numeric = df_numeric.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "برای فیچر زیر از روش محاسبه تعداد کلمات استفاده کرده و سپس مقدار آن متناظر آن را محاسبه کرده "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_count = df['Tweet content']\n",
    "tweet_count2 = tweet_count.apply(lambda x:  str(x) )\n",
    "cv = CountVectorizer()\n",
    "tf = cv.fit_transform(tweet_count2)\n",
    "word_count = cv.inverse_transform(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "فیچر های جدید را اضافه و فچیر های پردازش شده درمراحل بالا را در متغییر زیر ریخته"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_numeric['Word Count'] = word_count \n",
    "df_numeric['User Name'] = df['User Name']\n",
    "df_numeric['rank'] = df['rank']\n",
    "\n",
    "drp = df_numeric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "رسم ماتریس کوواریانس بر حسب هیتمپ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation_matrix(df):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    cmap = cm.get_cmap('jet', 30)\n",
    "    ax1.imshow(df.corr(), interpolation=\"nearest\", cmap=cmap)\n",
    "    ax1.grid(True)\n",
    "    plt.title('')\n",
    "    labels= df.columns\n",
    "    ax1.set_xticklabels(labels,fontsize=6)\n",
    "    ax1.set_yticklabels(labels,fontsize=6)\n",
    "    plt.show()\n",
    "\n",
    "correlation_matrix(drp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "رسم رابطه فیچر ها بر حسب خروجی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure();\n",
    "plt.scatter(drp['Favs'],drp['rank'])\n",
    "plt.title('Favs')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure();\n",
    "plt.scatter(drp['RTs'],drp['rank'])\n",
    "plt.title('RTs')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure();\n",
    "plt.scatter(drp['reply'],drp['rank'])\n",
    "plt.title('reply')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure();\n",
    "plt.scatter(drp['tweets'],drp['rank'])\n",
    "plt.title('tweets')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure();\n",
    "plt.scatter(drp['likes'],drp['rank'])\n",
    "plt.title('likes')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure();\n",
    "plt.scatter(drp['reply'],drp['rank'])\n",
    "plt.title('reply')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure();\n",
    "plt.scatter(drp['Followers'],drp['rank'])\n",
    "plt.title('Followers')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure();\n",
    "plt.scatter(drp['Following'],drp['rank'])\n",
    "plt.title('Following')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure();\n",
    "plt.scatter(drp['Listed'],drp['rank'])\n",
    "plt.title('Listed')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "جداکردن داده های ترین تست و ولیدیشن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_validation , test = train_test_split(drp,test_size=0.25, random_state=42)\n",
    "train , validation = train_test_split(drp,test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "متغیر اول برای محاسبه اررور در هر روش و متغییر دوم بین روش های مختلف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors_array = []\n",
    "\n",
    "all_errors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "محاسبه  ارور سیمپل رگرشن  بر اساس فیچر های مختلف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train['likes'].values.reshape(-1,1),train['rank'])\n",
    "y_pred = regr.predict(test['likes'].values.reshape(-1,1))\n",
    "error = mean_squared_error(test['rank'].values.reshape(-1,1),y_pred)\n",
    "\n",
    "errors_array.append(error)\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train['Favs'].values.reshape(-1,1),train['rank'])\n",
    "y_pred = regr.predict(test['Favs'].values.reshape(-1,1))\n",
    "error = mean_squared_error(test['rank'].values.reshape(-1,1),y_pred)\n",
    "\n",
    "errors_array.append(error)\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train['RTs'].values.reshape(-1,1),train['rank'])\n",
    "y_pred = regr.predict(test['RTs'].values.reshape(-1,1))\n",
    "error = mean_squared_error(test['rank'].values.reshape(-1,1),y_pred)\n",
    "errors_array.append(error)\n",
    "\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train['Followers'].values.reshape(-1,1),train['rank'])\n",
    "y_pred = regr.predict(test['Followers'].values.reshape(-1,1))\n",
    "error = mean_squared_error(test['rank'].values.reshape(-1,1),y_pred)\n",
    "errors_array.append(error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train['Listed'].values.reshape(-1,1),train['rank'])\n",
    "y_pred = regr.predict(test['Listed'].values.reshape(-1,1))\n",
    "error = mean_squared_error(test['rank'].values.reshape(-1,1),y_pred)\n",
    "errors_array.append(error)\n",
    "\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train['tweets'].values.reshape(-1,1),train['rank'])\n",
    "y_pred = regr.predict(test['tweets'].values.reshape(-1,1))\n",
    "error = mean_squared_error(test['rank'].values.reshape(-1,1),y_pred)\n",
    "errors_array.append(error)\n",
    "all_errors.append(error)\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train['reply'].values.reshape(-1,1),train['rank'])\n",
    "y_pred = regr.predict(test['reply'].values.reshape(-1,1))\n",
    "error = mean_squared_error(test['rank'].values.reshape(-1,1),y_pred)\n",
    "errors_array.append(error)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "نمایش خطا ها متناظر با فیچر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pd.Series(errors_array ,['likes','Favs','RTs','Followers','Listed','tweets','reply']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "محاسبه کمترین خطا"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min(pd.Series(errors_array ,['likes','Favs','RTs','Followers','Listed','tweets','reply']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تبدیل فیچر بوزنیم به مقادیر عددی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "cat_username = le.fit_transform(drp['User Name'])\n",
    "drp['username_categories'] = cat_username\n",
    "ndrp = drp[['likes','Favs','RTs','Followers','Listed','tweets','reply']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " اهمیت فیچر ها بر حسب کلاسیفایر درختی و رسم نمودار"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = ExtraTreesClassifier(n_estimators=10,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(ndrp, drp['rank'])\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(ndrp.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(ndrp.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(ndrp.shape[1]), ndrp.columns)\n",
    "plt.xlim([-1, ndrp.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مالتیپل رگرشن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected = ['likes','Favs','RTs','Followers']\n",
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train[selected],train['rank'])\n",
    "y_pred = regr.predict(test[selected])\n",
    "error = mean_squared_error(test['rank'],y_pred)\n",
    "all_errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "محاسبه ریج رگرشن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = [0.5,1.0,2.0,5]\n",
    "ridge_errors = []\n",
    "\n",
    "for i in alphas:\n",
    "    clf = Ridge(alpha=i,fit_intercept=True, max_iter=None,\n",
    "      normalize=True, random_state=None, solver='auto', tol=0.001)\n",
    "    clf.fit(train[selected], train['rank'])\n",
    "    y_pred = regr.predict(test[selected])\n",
    "    error = mean_squared_error(test['rank'],y_pred)\n",
    "    ridge_errors.append(error)\n",
    "\n",
    "\n",
    "all_errors.append(min(ridge_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "محاسبه لسو رگرشن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alphas = [0.5,1.0,2.0,5]\n",
    "lasso_errors = []\n",
    "\n",
    "for i in alphas:\n",
    "    clf = Lasso(alpha=i,selection = \"cyclic\", warm_start=True)\n",
    "    clf.fit(train[selected], train['rank'])\n",
    "    y_pred = regr.predict(test[selected])\n",
    "    error = mean_squared_error(test['rank'],y_pred)\n",
    "    lasso_errors.append(error)\n",
    "\n",
    "\n",
    "all_errors.append(min(lasso_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "انتخاب مدل بر اساس لسو وسپس فیت کردن مدل براساس ریج"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "model_features = ['User Name','likes','Favs','RTs','Followers','Listed','tweets','reply','Word Count'];\n",
    "\n",
    "lasso_cv = LassoCV()\n",
    "select_from_model = SelectFromModel(lasso_cv, threshold=2e-4)\n",
    "select_from_model.fit(train_validation[model_features],train_validation['rank'])\n",
    "\n",
    "selected_data = select_from_model.transform(train_validation[model_features])\n",
    "selected_features_index = select_from_model.get_support(True)\n",
    "selected_features = [ model_features[i] for i in selected_features_index ]\n",
    "\n",
    "alphas = np.logspace(-4,4,20)\n",
    "ridge_lasso_model = linear_model.RidgeCV(alphas=alphas,cv=5,normalize=True)\n",
    "ridge_lasso_model.fit(selected_data,train_validation['rank'])\n",
    "\n",
    "\n",
    "ridge_lasso_model_mse = mean_squared_error(test['rank'],ridge_lasso_model.predict(test[selected_features]))\n",
    "errors_array.append(ridge_lasso_model_mse)\n",
    "all_errors.append(ridge_lasso_model_mse)\n",
    "\n",
    "\n",
    "print(\"mse ridge_lasso_model tTest : %s\" %mean_squared_error(test['rank'],ridge_lasso_model.predict(test[selected_features])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "فوروارد استپوایز تعیین اهمیت فیچر ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "\n",
    "\n",
    "fs_features_array = []\n",
    "fs_remaining = list(model_features)\n",
    "\n",
    "while len(fs_remaining) > 0:\n",
    "    \n",
    "    rss = sys.float_info.max\n",
    "\n",
    "    for r in fs_remaining:\n",
    "        _f = fs_features_array + [r] \n",
    "        model_i = LinearRegression()\n",
    "        model_i.fit(train[_f], train['rank'])\n",
    "        rss_model_i = mean_squared_error(test['rank'], model_i.predict(test[_f]))\n",
    "        \n",
    "        if(rss_model_i < rss):\n",
    "            rss = rss_model_i\n",
    "            last = r\n",
    "            \n",
    "    if(last is not None):\n",
    "        fs_remaining.remove(last)        \n",
    "        fs_features_array.append(last)\n",
    "\n",
    "\n",
    "print(fs_features_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بکوارد استپوایز تعیین اهمیت فیچر ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_features_array = []\n",
    "bs_remaining = list(model_features)\n",
    "\n",
    "while len(bs_remaining) > 0:\n",
    "    \n",
    "    rss = sys.float_info.max\n",
    "\n",
    "    for r in bs_remaining:\n",
    "        \n",
    "        __list = list(bs_remaining)\n",
    "        __list.remove(r)\n",
    "\n",
    "        if(len(__list) > 0):\n",
    "            model_i = LinearRegression()\n",
    "            model_i.fit(train[__list], train['rank'])\n",
    "            rss_model_i = mean_squared_error(test['rank'],model_i.predict(test[__list]))\n",
    "        \n",
    "        if(rss_model_i < rss):\n",
    "            rss = rss_model_i\n",
    "            bs_last = r\n",
    "            \n",
    "    if(bs_last is not None):\n",
    "        bs_remaining.remove(bs_last)        \n",
    "        bs_features_array.append(bs_last)\n",
    "\n",
    "\n",
    "print(bs_features_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "روش نزدیکترین همسایه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "nneighbors = neighbors.KNeighborsRegressor(1, weights='distance',metric='minkowski')\n",
    "nneighbors.fit(train_validation[model_features], train_validation['rank']);\n",
    "nn_prediction = nneighbors.predict(test[model_features])\n",
    "\n",
    "\n",
    "\n",
    "nneighbors_mse = mean_squared_error(test['rank'],nn_prediction)\n",
    "errors_array.append(nneighbors_mse)\n",
    "\n",
    "all_errors.append(nneighbors_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "روش چند نزدیک ترین همسایه وانتخاب بهترین k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "knn = [2,4,6,8,10,15,20,25,35,50,100]\n",
    "\n",
    "knneighbors_errors_array = []\n",
    "for i in knn:\n",
    "    nneighbors = neighbors.KNeighborsRegressor(i, weights='distance',metric='minkowski')\n",
    "    nneighbors.fit(train_validation[model_features], train_validation['rank']);\n",
    "    nn_prediction = nneighbors.predict(test[model_features])\n",
    "    nneighbors_mse = mean_squared_error(test['rank'],nn_prediction)\n",
    "    knneighbors_errors_array.append(nneighbors_mse)\n",
    "\n",
    "all_errors.append(min(knneighbors_errors_array))\n",
    "\n",
    "\n",
    "\n",
    "from kernel_regression import KernelRegression\n",
    "\n",
    "kernel_rss = sys.float_info.max\n",
    "\n",
    "for i,_kernel in enumerate(['linear','polynomial','sigmoid']):\n",
    "    kr = KernelRegression(kernel=_kernel)\n",
    "    kr.fit(train[model_features],train['rank'])\n",
    "    ck_rss = mean_squared_error(test['rank'],kr.predict(test[model_features]))\n",
    "    if(ck_rss < kernel_rss):\n",
    "        kernel_rss =ck_rss\n",
    "        selected_kernel = _kernel\n",
    "    \n",
    "print(selected_kernel)\n",
    "print(kernel_rss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kr = KernelRegression(kernel=selected_kernel)\n",
    "kr.fit(train[model_features],train['rank'])\n",
    "kernel_mse = mean_squared_error(test['rank'],kr.predict(test[model_features]))\n",
    "errors_array.append(kernel_mse)\n",
    "\n",
    "all_errors.append(kernel_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "روش کرنل رگرشن با امتحان چند کرنل زیر و انتخاب بهترین آن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from kernel_regression import KernelRegression\n",
    "\n",
    "kernel_rss = sys.float_info.max\n",
    "\n",
    "for i,_kernel in enumerate(['linear','polynomial','sigmoid']):\n",
    "    kr = KernelRegression(kernel=_kernel)\n",
    "    kr.fit(train[model_features],train['rank'])\n",
    "    ck_rss = mean_squared_error(test['rank'],kr.predict(test[model_features]))\n",
    "    if(ck_rss < kernel_rss):\n",
    "        kernel_rss =ck_rss\n",
    "        selected_kernel = _kernel\n",
    "    \n",
    "print(selected_kernel)\n",
    "print(kernel_rss)\n",
    "\n",
    "\n",
    "kr = KernelRegression(kernel=selected_kernel)\n",
    "kr.fit(train[model_features],train['rank'])\n",
    "kernel_mse = mean_squared_error(test['rank'],kr.predict(test[model_features]))\n",
    "errors_array.append(kernel_mse)\n",
    "\n",
    "all_errors.append(kernel_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "روش رگرسون ناحیه ای وزن دار"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bisect import insort_left\n",
    "import math\n",
    "\n",
    "lwr_features = model_features\n",
    "\n",
    "def locally_weighted_regression(query, samples,target, alpha):\n",
    "  target = np.mat(target).T\n",
    "  samples = np.insert(samples, obj=0, values=1, axis=1)\n",
    "  query = np.insert(query, obj=0, values=1)\n",
    "  weights = get_weights(query, samples, alpha)\n",
    "  Beta = (samples.T * weights * samples).I * samples.T * weights * target\n",
    "  prediction = np.matrix.dot(Beta.A.T, query)\n",
    "\n",
    "  return prediction\n",
    "\n",
    "\n",
    "def get_weights(query, X, alpha):\n",
    "  count = len(X)               \n",
    "  region = int(round(alpha * count)) \n",
    "  Weights = np.identity(count)        \n",
    "\n",
    "  sort = []\n",
    "  for i,row in enumerate(X):\n",
    "    diff = get_norm(row - query)\n",
    "    insort_left(sort, diff)\n",
    "    Weights[i][i] = diff\n",
    "  normalization = 1 / sort[region - 1]\n",
    "  Weights = Weights * normalization\n",
    "  for i in range(0, len(Weights)):\n",
    "    Weights[i][i] = (1 - (Weights[i][i] ** 3)) ** 3 if Weights[i][i] < 1 else 0\n",
    "\n",
    "  return np.mat(Weights)\n",
    "\n",
    "\n",
    "def get_norm(v):\n",
    "  vp = np.matrix.dot(v, v.T)\n",
    "  return math.sqrt(vp)\n",
    "\n",
    "X_ = np.mat(train[lwr_features].as_matrix())\n",
    "y_ = np.mat(train['rank'].as_matrix())\n",
    "query = test[lwr_features].as_matrix()\n",
    "\n",
    "y_predicted = []\n",
    "for x in query:\n",
    "    y_predicted.append(locally_weighted_regression(x, X_, y_, 0.35)[0])\n",
    "\n",
    "\n",
    "locally_weighted_regression_mae = mean_squared_error(test['rank'],y_predicted)\n",
    "errors_array.append(locally_weighted_regression_mse)\n",
    "\n",
    "all_errors.append(locally_weighted_regression_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "روش ابتکاری -انتخاب فیچر ها بر اساس لسو و سپس یادگیری براساس رگرسیون ناحیه ای وزندار"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV()\n",
    "select_from_model = SelectFromModel(lasso_cv, threshold=2e-4)\n",
    "select_from_model.fit(train_validation[model_features],train_validation['rank'])\n",
    "\n",
    "selected_data = select_from_model.transform(train_validation[model_features])\n",
    "selected_features_index = select_from_model.get_support(True)\n",
    "selected_features = [ model_features[i] for i in selected_features_index ]\n",
    "\n",
    "\n",
    "X_ = np.mat(train[selected_features].as_matrix())\n",
    "y_ = np.mat(train['rank'].as_matrix())\n",
    "query = test[selected_features].as_matrix()\n",
    "\n",
    "\n",
    "y_predicted = []\n",
    "for x in query:\n",
    "    y_predicted.append(locally_weighted_regression(x, X_, y_, 0.35)[0])\n",
    "\n",
    "\n",
    "locally_weighted_regression_mse = mean_squared_error(test['rank'],y_predicted)\n",
    "errors_array.append(locally_weighted_regression_mse)\n",
    "\n",
    "all_errors.append(locally_weighted_regression_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "پرینت تمامی اررور های محاسبه شده در روش های مراحل قبل"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pd.Series(all_errors ,['single','multiple','ridge','lasso','ridge-lasso','1nn','knn','kernel','locally weighted regression','ابتکاری']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مشاهده میشود روش کا نزدیکترین همسایه کمترین میزان خطا را دارد سپس پیشبینی رنک بر اساس داده های تست"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx = pd.read_excel('StudentTest.xlsx', sheet_name=None)\n",
    "\n",
    "\n",
    "dfx = dfx.fillna(0)\n",
    "dfx = dfx.drop(['URLs'],axis=1)\n",
    "\n",
    "\n",
    "df_numericx = dfx[['Favs','RTs','Followers','Following','Listed', 'likes','tweets','reply']]\n",
    "#df_numeric[np.abs(df_numeric.values - df_numeric.values.mean()) <= (3*df_numeric.values.std())]\n",
    "df_numericx[~(np.abs(df_numericx.values-df_numericx.values.mean()) > (3*df_numericx.values.std()))]\n",
    "df_numericx = df_numericx.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "tweet_countx = dfx['Tweet content']\n",
    "tweet_count2x = tweet_countx.apply(lambda x:  str(x) )\n",
    "cvx = CountVectorizer()\n",
    "tfx = cv.fit_transform(tweet_count2x)\n",
    "word_countx = cv.inverse_transform(tfx)\n",
    "\n",
    "df_numericx['Word Count'] = word_countx\n",
    "df_numericx['User Name'] = dfx['User Name']\n",
    "\n",
    "drpx= df_numericx\n",
    "\n",
    "model_features = ['likes','Favs','RTs','Followers','Listed','tweets','reply'];\n",
    "\n",
    "nneighbors = neighbors.KNeighborsRegressor(50, weights='distance',metric='minkowski')\n",
    "nneighbors.fit(drp[model_features], drp['rank']);\n",
    "prediction = nneighbors.predict(drpx[model_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ذخیره در فایل "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx['rank'] = prediction\n",
    "\n",
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "dfx.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
